# -*- coding: utf-8 -*-
"""PTE_DL5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/karsarobert/Deep-Learning-2023/blob/main/05/PTE_DL5.ipynb

# Deep Learning gyakorlat


## 5. gyakorlat: konvol√∫ci√≥s h√°l√≥zat
### 2023. okt√≥ber 4.

forr√°s: https://github.com/mrdbourke/tensorflow-deep-learning
"""

!rm -r *

# download data
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip

# Unzip the downloaded file
import zipfile
zip_ref = zipfile.ZipFile("pizza_steak.zip")
zip_ref.extractall()
zip_ref.close()

# for colab
# !unzip -q pizza_steak.zip

# remove extra data
!rm -r __MACOSX
!rm -r pizza_steak.zip
!rm -r pizza_steak/.DS_Store
!rm -r pizza_steak/train/.DS_Store
!rm -r pizza_steak/test/.DS_Store

!ls pizza_steak/train/pizza

"""Az adatokat tartalmaz√≥ k√∂nyvt√°rak √©s azok tartalma"""

import os

# Walk through pizza_steak directory and list number of files
for dirpath,dirnames,filenames in os.walk("pizza_steak"):
  print("There are {} directories and {} images in {}".format(len(dirnames),len(filenames),dirpath))

"""#Feladat
K√©sz√≠tsen list√°t az √∂sszes f√°jlr√≥l egy file_path list√°ba
"""

files_path = []

for root, dirs, files in os.walk("pizza_steak/"):
   for name in files:
      files_path.append(root + '/'  + name)

files_path[900:905]



"""##Egy k√∂nyvt√°rban tal√°lhat√≥ f√°jlok megsz√°ml√°l√°sa"""

# Another way to find out how many images are in a file
num_steak_images_train = len(os.listdir("pizza_steak/train/steak"))
num_steak_images_train

"""#Feladat
k√©sz√≠ts√ºnk egy pizza_train_files nev≈± list√°t amely a tr√©ning adatokb√≥l az √∂sszes pizza mapp√°ban l√©v≈ë f√°jlnevet tartalmazza
"""

pizza_train_files = os.listdir("pizza_steak/train/pizza") # mi t√∂rt√©nik ha csak 'pizza_steak/train' mapp√°t adjuk meg?
pizza_train_files

import pathlib

data_dir = pathlib.Path("pizza_steak/train")
sorted([item.name for item in data_dir.glob("*")])

data_dir.glob("*")

"""##Az oszt√°lyoz√°si feladathoz tartoz√≥ oszt√°lynevek"""

# Get the classnames programmatically
import pathlib
import numpy as np
data_dir = pathlib.Path("pizza_steak/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")])) # Create a list of class_nmaes from the subdirectories
print(class_names)

"""##Egy k√©p megjelen√≠t√©se"""

# Lets visualize our images
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

def view_random_image(target_dir,target_class):
  # Setup the target directory (we'l view images from here)
  target_folder = target_dir + target_class

  # Get a random image path
  random_image = random.sample(os.listdir(target_folder),1) # egy lista lesz a kimenet de most csak 1 k√©ppel

  # Read in the image and plot it using matplotlib
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"Image shape: {img.shape}") # show the shape of the image

  return img

# View a random image from training dataset
img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

# View the image shape
img.shape # return width,height,color channels

"""#Fealdat
k√©sz√≠tsen a fentiek alapj√°n egy olyan f√ºggv√©nyt ami param√©terk√©nt √°tveszi a k√∂nyvt√°r nev√©t √©s abban tal√°lhat√≥ k√©pekb≈ël v√©letlenszer≈±en kiv√°laszt 25 db-ot majd √°br√°zolja azokat 5x5 plotban
"""

random_image = random.sample(os.listdir('pizza_steak/train/pizza'),25) # egy lista lesz a kimenet de most csak 1 k√©ppel

def view_random_images(target_dir, target_class):
  plt.figure(figsize=(15,15))
  for i in range(25):

    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    img = mpimg.imread(target_dir + "/" + random_image[i])
    plt.imshow(img)
    plt.xlabel(target_class)
  plt.show()

view_random_images('pizza_steak/train/pizza', 'pizza')

"""#Adatok norm√°l√°sa

Sok g√©pi tanul√°si modell, bele√©rtve a neur√°lis h√°l√≥zatokat is, a 0 √©s 1 k√∂z√∂tti √©rt√©keket r√©szes√≠ti el≈ënyben. Ennek ismeret√©ben a k√©pekkel val√≥ munka egyik leggyakoribb el≈ëfeldolgoz√°si l√©p√©se a pixel√©rt√©kek sk√°l√°z√°sa (m√°s n√©ven normaliz√°l√°sa) a k√©pt√°bl√°k 255-tel val√≥ oszt√°s√°val. (mivel 255 a maxim√°lis pixel√©rt√©k).
"""

# Get all the pixel values between 0 & 1
img/255.

"""#√âp√≠ts√ºnk egy konvol√∫ci√≥s neur√°lis h√°l√≥zatot
m√≥dszer:

1. T√∂lts√ºk be a k√©peinket
2. A k√©pek el≈ëfeldolgoz√°sa
3. Egy CNN modell √©p√≠t√©se, hogy mint√°kat tal√°ljon a k√©peinken.
4. Modell√ºnk √∂ssze√°ll√≠t√°sa
5. A modell illeszt√©se a k√©pz√©si adatainkhoz
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# set the seed
tf.random.set_seed(42)

# preprocess data (get all of the pixel values between 0 & 1, also called as scaling/normalization)
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# Setup paths to our data directories
train_dir = "pizza_steak/train"
test_dir = "pizza_steak/test"

# Import data from directories and turn it into batches
train_data = train_datagen.flow_from_directory(directory=train_dir,
                                               batch_size=32,
                                               target_size=(224,224),
                                               class_mode="binary",
                                               seed=42)
valid_data = valid_datagen.flow_from_directory(directory=test_dir,
                                               batch_size=32,
                                               target_size=(224,224),
                                               class_mode="binary",
                                               seed=42)

# Build a CNN model (same as the Tiny VGG on the CNN explainer website)
model_1 = tf.keras.models.Sequential([
   tf.keras.layers.Conv2D(filters=10,
                          kernel_size=3,
                          activation="relu",
                          input_shape=(224,224,3)),
   tf.keras.layers.Conv2D(10,3,activation="relu"),
   tf.keras.layers.MaxPool2D(pool_size=2,
                             padding="valid"),
   tf.keras.layers.Conv2D(10,3,activation="relu"),
   tf.keras.layers.Conv2D(10,3,activation="relu"),
   tf.keras.layers.MaxPool2D(2),
   tf.keras.layers.Flatten(),
   tf.keras.layers.Dense(1,activation="sigmoid")
])

# Compile or CNN
model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),
                optimizer='adam', # tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

# Fit the model
history_1 = model_1.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=valid_data,
                        validation_steps=len(valid_data))

model_1.summary()

model_1.save('model_1.h5')

"""#Oszt√°lyoz√≥ √©p√≠t√©se teljesen √∂sszek√∂t√∂tt r√©tegek felhaszn√°l√°s√°val"""

# Set random seed
tf.random.set_seed(42)

# Create model to replicate the TensorFlow Playground model
model_2 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224,224,3)),
    tf.keras.layers.Dense(4,activation="relu"),
    tf.keras.layers.Dense(4,activation="relu"),
    tf.keras.layers.Dense(1,activation="sigmoid")
])

# Compile model
model_2.compile(loss="binary_crossentropy",
               optimizer=tf.keras.optimizers.Adam(),
               metrics=["accuracy"])

# Fit model
history_2 = model_2.fit(train_data,
                       epochs=5,
                       steps_per_epoch=len(train_data),
                       validation_data=valid_data,
                       validation_steps=len(valid_data))

model_2.summary()

"""#Feladat √©p√≠ts√ºnk modellt az el≈ëz≈ëek szerint 3 rejtett r√©teggel, r√©tegenk√©nt 100 neuronnal"""

tf.random.set_seed(42)

# create model (same as above but let's improve it)
model_3 = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224,224,3)),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(100,activation="relu"),
    tf.keras.layers.Dense(1,activation="sigmoid")
])

# Compile model
model_3.compile(loss="binary_crossentropy",
               optimizer=tf.keras.optimizers.Adam(),
               metrics=["accuracy"])

# Fit model
history_3 = model_3.fit(train_data,
                       epochs=5,
                       steps_per_epoch=len(train_data),
                       validation_data=valid_data,
                       validation_steps=len(valid_data))

model_3.summary()

"""#Modellk√©sz√≠t√©s folyamata:
1. Vizsg√°ljuk az adatokat (vizualiz√°l√°s, vizualiz√°l√°s, vizualiz√°l√°s)
2. Adatok el≈ëfeldolgoz√°sa (el≈ëk√©sz√≠tett√ºk a modell√ºnk sz√°m√°ra, a f≈ë l√©p√©s itt a m√©retez√©s/normaliz√°l√°s √©s az adataink k√∂tegekk√© alak√≠t√°sa volt).
3. K√©sz√≠ts√ºnk egy modellt (kezdj√ºk egy alapvonallal)
4. Modell illeszt√©se
5. A modell ki√©rt√©kel√©se
6. A k√ºl√∂nb√∂z≈ë param√©terek be√°ll√≠t√°sa √©s a modell jav√≠t√°sa (pr√≥b√°ljuk meg legy≈ëzni az alapvonalunkat)

# 1. Adatok vizsg√°lata
B√°rmilyen adatokkal is van dolga, √©rdemes legal√°bb 10-100 mint√°t vizualiz√°lni, hogy elkezdje fel√©p√≠teni saj√°t ment√°lis modellj√©t az adatokr√≥l.

Eset√ºnkben √©szrevehetj√ºk, hogy a steak-k√©pek √°ltal√°ban s√∂t√©tebb sz√≠n≈±ek, m√≠g a pizza-k√©pek ink√°bb egy hat√°rozott k√∂r alak√∫ k√∂z√©pen. Ezek olyan mint√°k lehetnek, amelyeket a neur√°lis h√°l√≥zatunk felismer.

Azt is √©szreveheti, ha az adatai k√∂z√ºl n√©h√°nyat elrontott (p√©ld√°ul rossz c√≠mke van rajta), √©s elkezdheti fontolgatni, hogyan jav√≠thatn√° ki.
"""

# Visualize data (requires function 'view_random_image' above)
plt.figure()
plt.subplot(1, 2, 1)
steak_img = view_random_image("pizza_steak/train/", "steak")
plt.subplot(1, 2, 2)
pizza_img = view_random_image("pizza_steak/train/", "pizza")

"""#2. Az adatok el≈ëfeldolgoz√°sa (el≈ëk√©sz√≠t√©se a modellhez)
A g√©pi tanul√°si projekt egyik legfontosabb l√©p√©se a gyakorl√≥- √©s tesztk√©szlet l√©trehoz√°sa.

Eset√ºnkben az adataink m√°r fel vannak osztva k√©pz√©si √©s tesztk√©szletekre. Egy m√°sik lehet≈ës√©g itt az lehet, hogy l√©trehozunk egy valid√°ci√≥s k√©szletet is, de ezt most hagyjuk.

Egy k√©poszt√°lyoz√°si projekt eset√©ben az a szok√°sos, hogy az adatokat tr√©ning √©s teszt k√∂nyvt√°rakra osztjuk, √©s mindegyikben almapp√°kat hozunk l√©tre az egyes oszt√°lyok sz√°m√°ra.

Kezdetben defini√°ljuk a k√©pz√©si √©s tesztk√∂nyvt√°rak el√©r√©si √∫tvonalait.
"""

# Define training and test directory paths
train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"

"""A k√∂vetkez≈ë l√©p√©s√ºnk az lesz, hogy az adatainkat k√∂tegekk√© alak√≠tjuk.

A t√©tel az adathalmaz egy kis r√©szhalmaza, amelyet a modell a k√©pz√©s sor√°n megvizsg√°l. P√©ld√°ul ahelyett, hogy egyszerre 10 000 k√©pet vizsg√°ln√°nk meg, √©s pr√≥b√°ln√°nk kital√°lni a mint√°kat, a modell egyszerre csak 32 k√©pet n√©zhet meg.

Ezt t√∂bb okb√≥l is fontos:

A 10 000 k√©p (vagy ann√°l t√∂bb) nem biztos, hogy elf√©r a processzor (GPU) mem√≥ri√°j√°ban.
Ha 10 000 k√©p mint√°it pr√≥b√°ln√°nk egy csap√°sra megtanulni, az azt eredm√©nyezhetn√©, hogy a modell nem tudna nagyon j√≥l tanulni.
Mi√©rt 32?

[A 32-es k√∂tegm√©ret j√≥t tesz az eg√©szs√©g√©nek.](https://twitter.com/ylecun/status/989610208497360896?s=20)

:-), sokf√©le k√∂tegm√©retet haszn√°lhat, de a 32-es m√©ret nagyon hat√©konynak bizonyult sokf√©le felhaszn√°l√°si esetben, √©s gyakran alap√©rtelmezett sok adatel≈ëfeldolgoz√°si funkci√≥ eset√©ben.

Ahhoz, hogy adatainkat k√∂tegekk√© alak√≠tsuk, el≈ësz√∂r l√©trehozzuk az ImageDataGenerator egy-egy p√©ld√°ny√°t minden egyes adathalmazunkhoz.
"""

# Create train and test data generators and rescale the data
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)

"""Az ImageDataGenerator oszt√°ly seg√≠t a k√©pek k√∂tegekbe rendez√©s√©ben, valamint a modellbe val√≥ bet√∂lt√©s√ºk k√∂zbeni transzform√°ci√≥k elv√©gz√©s√©ben.

Tal√°n √©szrevetted a rescale param√©tert. Ez egy p√©lda az √°ltalunk v√©gzett transzform√°ci√≥kra.

Eml√©kszel, hogy kor√°bban import√°ltunk egy k√©pet, amelynek pixel√©rt√©kei 0 √©s 255 k√∂z√∂tt voltak?

A rescale param√©ter az 1/255-tel egy√ºtt olyan, mintha azt mondan√°nk, hogy "osszuk el az √∂sszes pixel√©rt√©ket 255-tel". Ez azt eredm√©nyezi, hogy az √∂sszes k√©pet import√°ljuk, √©s a pixel√©rt√©keiket normaliz√°ljuk (0 √©s 1 k√∂z√© alak√≠tjuk).

üîë Megjegyz√©s: Tov√°bbi transzform√°ci√≥s lehet≈ës√©gek√©rt, p√©ld√°ul az adatok n√∂vel√©s√©√©rt (ezt k√©s≈ëbb l√°tjuk), olvassa el az ImageDataGenerator dokument√°ci√≥j√°t.

Most, hogy m√°r van n√©h√°ny ImageDataGenerator p√©ld√°nyunk, a flow_from_directory met√≥dus seg√≠ts√©g√©vel bet√∂lthetj√ºk a k√©peinket a megfelel≈ë k√∂nyvt√°rakb√≥l.
"""

# Turn it into batches
train_data = train_datagen.flow_from_directory(directory=train_dir,
                                               target_size=(224, 224),
                                               class_mode='binary',
                                               batch_size=32)

test_data = test_datagen.flow_from_directory(directory=test_dir,
                                             target_size=(224, 224),
                                             class_mode='binary',
                                             batch_size=32)

"""Csod√°latos! √ögy t≈±nik, hogy a k√©pz√©si adathalmazunk 1500 k√©pet tartalmaz, amelyek 2 oszt√°lyba tartoznak (pizza √©s steak), √©s a tesztadathalmazunk 500 k√©pet tartalmaz, amelyek szint√©n 2 oszt√°lyba tartoznak.

N√©h√°ny dolog:

A k√∂nyvt√°rak fel√©p√≠t√©se miatt az oszt√°lyokat a train_dir √©s a test_dir alk√∂nyvt√°rak nevei alapj√°n k√∂vetkeztetj√ºk ki.
A target_size param√©ter meghat√°rozza a k√©peink bemeneti m√©ret√©t (magass√°g, sz√©less√©g) form√°tumban.
A class_mode 'binary' √©rt√©ke hat√°rozza meg az oszt√°lyoz√°si probl√©m√°nk t√≠pus√°t. Ha kett≈ën√©l t√∂bb oszt√°lyunk lenne, akkor a 'categorical' √©rt√©ket haszn√°ln√°nk.
A batch_size hat√°rozza meg, hogy h√°ny k√©p lesz az egyes t√©telekben, mi 32-t haszn√°ltunk, ami megegyezik az alap√©rtelmezett √©rt√©kkel.
A train_data objektum vizsg√°lat√°val megn√©zhetj√ºk a k√∂tegelt k√©peinket √©s a c√≠mk√©ket.
"""

# Get a sample of the training data batch
images, labels = train_data.next() # get the 'next' batch of images/labels
len(images), len(labels)

# Get the first image
images[0], images[0].shape

# View the first batch of labels
labels

"""#3. Hozzon l√©tre egy modellt (kezdje egy alapvonallal).
Tal√°n elgondolkodott azon, hogy milyen legyen az alap√©rtelmezett modellarchitekt√∫ra.

√âs az igazs√°g az, hogy erre a k√©rd√©sre sokf√©le v√°lasz lehets√©ges.

Egy egyszer≈± heurisztika a sz√°m√≠t√≥g√©pes l√°t√°smodellekhez az, hogy azt a modellarchitekt√∫r√°t haszn√°ljuk, amelyik a legjobban teljes√≠t az ImageNet-en (a k√ºl√∂nb√∂z≈ë sz√°m√≠t√≥g√©pes l√°t√°smodellek √∂sszehasonl√≠t√°s√°ra szolg√°l√≥, v√°ltozatos k√©pek nagy gy≈±jtem√©nye).

Kezdetben azonban j√≥, ha egy kisebb modellt √©p√≠t√ºnk, hogy megszerezz√ºnk egy alaperedm√©nyt, amelyet megpr√≥b√°lunk jav√≠tani.

üîë Megjegyz√©s: A m√©lytanul√°sban a kisebb modell gyakran olyan modellt jelent, amely kevesebb r√©teggel rendelkezik, mint a technika jelenlegi √°ll√°sa (SOTA). P√©ld√°ul egy kisebb modell 3-4 r√©teggel rendelkezhet, m√≠g a legmodernebb modell, p√©ld√°ul a ResNet50 50+ r√©teggel rendelkezik.

Eset√ºnkben vegy√ºk a CNN explainer weboldal√°n tal√°lhat√≥ modell egy kisebb v√°ltozat√°t (a fenti model_1-et), √©s √©p√≠ts√ºnk egy 3 r√©teg≈± konvol√∫ci√≥s neur√°lis h√°l√≥zatot.
"""

# Make the creating of our model a little easier
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential

# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)
model_4 = Sequential([
  Conv2D(filters=10,
         kernel_size=3,
         strides=1,
         padding='valid',
         activation='relu',
         input_shape=(224, 224, 3)), # input layer (specify input shape)
  Conv2D(10, 3, activation='relu'),
  Conv2D(10, 3, activation='relu'),
  Flatten(),
  Dense(1, activation='sigmoid') # output layer (specify output shape)
])

"""Nagyszer≈±! K√©szen √°ll egy egyszer≈± konvol√∫ci√≥s neur√°lis h√°l√≥zati architekt√∫ra.

√âs a tipikus CNN strukt√∫r√°t k√∂veti:

Conv + ReLU r√©tegek (nemlinearit√°sok) -> √ñsszevon√≥ r√©teg -> Teljesen √∂sszekapcsolt (s≈±r≈± r√©teg) kimenetk√©nt.
Besz√©lj√ºnk a Conv2D r√©teg n√©h√°ny komponens√©r≈ël:

A "2D" azt jelenti, hogy a bemeneteink k√©tdimenzi√≥sak (magass√°g √©s sz√©less√©g), annak ellen√©re, hogy 3 sz√≠ncsatorn√°val rendelkeznek, a konvol√∫ci√≥kat minden csatorn√°n egyenk√©nt futtatjuk.
Sz≈±r≈ëk - ezek a "feature extractorok" sz√°ma, amelyek a k√©peinken fognak mozogni.
kernel_size - a sz≈±r≈ëink m√©rete, p√©ld√°ul egy (3, 3) (vagy csak 3) kernel_size azt jelenti, hogy minden sz≈±r≈ë 3x3 m√©ret≈± lesz, ami azt jelenti, hogy minden alkalommal egy 3x3 pixeles teret fog vizsg√°lni. Min√©l kisebb a kernel, ann√°l t√∂bb finomabb jellemz≈ët fog kinyerni.
stride - a k√©ppontok sz√°ma, amelyeken a sz≈±r≈ë √°thalad a k√©p lefed√©se sor√°n. Az 1 stride azt jelenti, hogy a sz≈±r≈ë minden egyes pixelen 1-szer 1-et mozog. 2 stride azt jelenti, hogy egyszerre 2 pixelt mozog.
padding - ez lehet 'same' vagy 'valid', az 'same' null√°kat ad a k√©p k√ºls≈ë oldal√°hoz, √≠gy a konvol√∫ci√≥s r√©teg kimenete megegyezik a bemenettel, m√≠g a 'valid' (alap√©rtelmezett) lev√°gja a felesleges pixeleket, ahol a sz≈±r≈ë nem f√©r el (pl. 224 pixel sz√©les osztva a 3 kernelm√©rettel (224/3 = 74.6) azt jelenti, hogy egyetlen pixel lesz lev√°gva a v√©g√©n.

Mi az a "feature"?

Feature-nek tekinthet≈ë a k√©p b√°rmely jelent≈ës r√©sze. A mi eset√ºnkben p√©ld√°ul egy feature lehet a pizza k√∂r alakja. Vagy egy steak k√ºls≈ë durva sz√©lei.

Fontos megjegyezni, hogy ezeket a jellemz≈ëket nem mi hat√°rozzuk meg, hanem a modell tanulja meg ≈ëket, mik√∂zben k√ºl√∂nb√∂z≈ë sz≈±r≈ëket alkalmaz a k√©pen.

üìñ Forr√°sok: Ha nagyszer≈± bemutat√≥t szeretn√©l l√°tni ezekr≈ël m≈±k√∂d√©s k√∂zben, mindenk√©ppen t√∂lts egy kis id≈ët az al√°bbiak √°tn√©z√©s√©vel:

[CNN Explainer Webpage](https://poloclub.github.io/cnn-explainer/) - nagyszer≈± vizu√°lis √°ttekint√©s sz√°mos olyan koncepci√≥r√≥l, amelyet itt k√≥ddal reproduk√°lunk.

Most, hogy a modell√ºnk k√©szen √°ll, ford√≠tsuk le.



"""

# Compile the model
model_4.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

"""Mivel bin√°ris oszt√°lyoz√°si probl√©m√°n dolgozunk (pizza vs. steak), a vesztes√©gf√ºggv√©ny, amit haszn√°lunk, a 'binary_crossentropy', ha t√∂bboszt√°lyos lenne, akkor valami olyasmit haszn√°ln√°nk, mint a 'categorical_crossentropy'.

Adam az √∂sszes alap√©rtelmezett be√°ll√≠t√°ssal az optimaliz√°torunk, az √©rt√©kel√©si m√©r≈ësz√°munk pedig a pontoss√°g.

#4. Modell illeszt√©se
A modell√ºnk √∂ssze√°llt, ideje illeszteni.

Itt k√©t √∫j param√©tert fogsz √©szrevenni:

A mi eset√ºnkben azt akarjuk, hogy a modell√ºnk az √∂sszes t√©telen v√©gigmenjen, √≠gy ez megegyezik a train_data hossz√°val (1500 k√©p 32 t√©telben = 1500/32 = ~47 l√©p√©s).
validation_steps - ugyanaz, mint fent, kiv√©ve a validation_data param√©tert (500 tesztk√©p 32-es t√©telekben = 500/32 = ~16 l√©p√©s).
"""

# Check lengths of training and test data generators
len(train_data), len(test_data)

# Fit the model
history_4 = model_4.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))

"""#5. A modell ki√©rt√©kel√©se
√ögy t≈±nik, a modell√ºnk tanul valamit.

N√©zz√ºk meg a k√©pz√©si g√∂rb√©it.
"""

# Plot the training curves
import pandas as pd
pd.DataFrame(history_4.history).plot(figsize=(10, 7));

"""Hmm, a vesztes√©gg√∂rb√©k alapj√°n √∫gy t≈±nik, hogy a modell√ºnk t√∫lilleszkedik a k√©pz√©si adathalmazhoz.

üîë Megjegyz√©s: Ha egy modell valid√°ci√≥s vesztes√©ge n√∂vekedni kezd, akkor val√≥sz√≠n≈±, hogy a modell t√∫lilleszkedik a k√©pz√©si adathalmazhoz. Ez azt jelenti, hogy a modell t√∫l j√≥l tanulja a k√©pz√©si adathalmazban l√©v≈ë mint√°kat, √©s √≠gy cs√∂kken az √°ltal√°nos√≠t√°si k√©pess√©ge a nem l√°tott adatokra.

A modell√ºnk k√©pz√©si teljes√≠tm√©ny√©nek tov√°bbi vizsg√°lat√°hoz v√°lasszuk sz√©t a pontoss√°gi √©s vesztes√©gg√∂rb√©ket.
"""

# Plot the validation and training data separately
def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  """
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();

# Check out the loss curves of model_4
plot_loss_curves(history_4)

# Check out our model's architecture
model_4.summary()

"""#6. A modell param√©tereinek be√°ll√≠t√°sa
A g√©pi tanul√°si modell illeszt√©se 3 l√©p√©sb≈ël √°ll:

Hozzon l√©tre egy alapvonalat.
Az alapvonal fel√ºlm√∫l√°sa egy nagyobb modell t√∫lilleszt√©s√©vel.
Cs√∂kkentse a t√∫lilleszt√©st.
Eddig a 0. √©s az 1. l√©p√©sen ment√ºnk kereszt√ºl.

√âs van m√©g n√©h√°ny dolog, amivel megpr√≥b√°lhatjuk tov√°bb t√∫lilleszteni a modell√ºnket:

N√∂velhetj√ºk a konvol√∫ci√≥s r√©tegek sz√°m√°t.
N√∂velj√ºk a konvol√∫ci√≥s sz≈±r≈ëk sz√°m√°t.
Adjunk hozz√° egy √∫jabb s≈±r≈± r√©teget a lap√≠tott r√©teg√ºnk kimenet√©hez.
De mi ehelyett ink√°bb arra fogunk koncentr√°lni, hogy a modell√ºnk k√©pz√©si g√∂rb√©it jobban egym√°shoz igaz√≠tsuk, m√°s sz√≥val a 2. l√©p√©st vessz√ºk √°t.

Mi√©rt fontos a t√∫lilleszt√©s cs√∂kkent√©se?

Ha egy modell t√∫l j√≥l teljes√≠t a k√©pz√©si adatokon, √©s rosszul a nem l√°tott adatokon, akkor nem sok haszn√°t venn√©nk, ha a val√≥ vil√°gban akarn√°nk haszn√°lni.

Tegy√ºk fel, hogy egy pizza vs. steak √©teloszt√°lyoz√≥ alkalmaz√°st k√©sz√≠t√ºnk, √©s a modell√ºnk nagyon j√≥l teljes√≠t a k√©pz√©si adatokon, de amikor a felhaszn√°l√≥k kipr√≥b√°lt√°k, nem kaptak t√∫l j√≥ eredm√©nyeket a saj√°t √©telk√©peiken, vajon j√≥ tapasztalat lenne ez?

Nem igaz√°n...

Teh√°t a k√∂vetkez≈ë modellekhez, amiket √©p√≠t√ºnk, sz√°mos param√©tert fogunk be√°ll√≠tani, √©s menet k√∂zben megvizsg√°ljuk a k√©pz√©si g√∂rb√©ket.

Nevezetesen, m√©g 2 modellt fogunk √©p√≠teni:

Egy ConvNet max poolinggal
Egy ConvNet max poolinggal √©s adatb≈ëv√≠t√©ssel.
Az els≈ë modell eset√©ben a m√≥dos√≠tott alapvet≈ë CNN-strukt√∫r√°t k√∂vetj√ºk:

Conv r√©tegek + ReLU r√©tegek (nemlinearit√°sok) + Max Pooling r√©tegek -> Fully connected (s≈±r≈± r√©teg) kimenetk√©nt.
√âp√≠ts√ºk fel. Ugyanazzal a szerkezettel fog rendelkezni, mint a model_4, de minden egyes konvol√∫ci√≥s r√©teg ut√°n egy MaxPool2D() r√©teggel.
"""

# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)
model_5 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(pool_size=2), # reduce number of features by half
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

# Compile model (same as model_4)
model_5.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

# Fit the model
history_5 = model_5.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))

"""Ok√©, √∫gy t≈±nik, hogy a modell√ºnk a max poolinggal (model_5) rosszabbul teljes√≠t a k√©pz√©si halmazon, de jobban a valid√°ci√≥s halmazon.

Miel≈ëtt megn√©zz√ºk a k√©pz√©si g√∂rb√©it, n√©zz√ºk meg az architekt√∫r√°j√°t.
"""

# Check out the model architecture
model_5.summary()

"""√âszrevetted, hogy mi t√∂rt√©nik itt a kimeneti alakzattal minden egyes MaxPooling2D r√©tegben?

Minden alkalommal megfelez≈ëdik. Ez gyakorlatilag azt jelenti, hogy a MaxPooling2D r√©teg veszi az egyes Conv2D r√©tegek kimeneteit, √©s azt mondja: "Csak a legfontosabb jellemz≈ëket akarom, a t√∂bbit≈ël szabadulj meg".

Min√©l nagyobb a pool_size param√©ter, ann√°l jobban fogja a max pooling r√©teg kiszor√≠tani a k√©pb≈ël a jellemz≈ëket. Ha azonban t√∫l nagy, a modell nem biztos, hogy k√©pes lesz b√°rmit is megtanulni.

Ennek a poolingnak az eredm√©nye az √∂sszes betan√≠that√≥ param√©ter jelent≈ës cs√∂kken√©s√©ben mutatkozik meg (8 861 a model_5 modellben √©s 477 431 a model_4 modellben).

Ideje megn√©zni a vesztes√©gg√∂rb√©ket.
"""

# Plot loss curves of model_5 results
plot_loss_curves(history_5)

"""#Adatb≈ëv√≠t√©s
Sz√©p! L√°thatjuk, hogy a k√©pz√©si g√∂rb√©k sokkal k√∂zelebb ker√ºlnek egym√°shoz. A valid√°ci√≥s vesztes√©g azonban √∫gy t≈±nik, hogy a v√©ge fel√© elkezd n√∂vekedni, ami viszont potenci√°lisan t√∫lilleszt√©shez vezethet.

Itt az ideje, hogy el≈ëvegy√ºk a tr√ºkk√∂k t√°rh√°z√°t, √©s kipr√≥b√°ljuk a t√∫lilleszt√©s megel≈ëz√©s√©nek egy m√°sik m√≥dszer√©t, az adatb≈ëv√≠t√©st.

El≈ësz√∂r megn√©zz√ºk, hogyan t√∂rt√©nik a k√≥ddal, majd megvitatjuk, hogy mit csin√°l.

Az adatn√∂vel√©s megval√≥s√≠t√°s√°hoz √∫jra kell √°ll√≠tanunk az ImageDataGenerator p√©ld√°nyainkat.
"""

# Create ImageDataGenerator training instance with data augmentation
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range=20, # k√©p forgat√°sa max 20 fokkal
                                             shear_range=0.2, # ny√≠r√°s
                                             zoom_range=0.2, # nagy√≠t√°s
                                             width_shift_range=0.2, # k√©p eltol√°sa
                                             height_shift_range=0.2, # k√©p eltol√°sa
                                             horizontal_flip=True) # v√≠zszintes tengely menti t√ºkr√∂z√©s

# Create ImageDataGenerator training instance without data augmentation
train_datagen = ImageDataGenerator(rescale=1/255.)

# Create ImageDataGenerator test instance without data augmentation
test_datagen = ImageDataGenerator(rescale=1/255.)

"""ü§î K√©rd√©s: Mi az az adatb≈ëv√≠t√©s?

[adatb≈ëv√≠t√©s tensorflow](https://www.tensorflow.org/tutorials/images/data_augmentation)

Az adatb≈ëv√≠t√©s a k√©pz√©si adataink megv√°ltoztat√°s√°nak folyamata, ami azt eredm√©nyezi, hogy azok v√°ltozatosabbak lesznek, √©s ez√°ltal a modelljeink √°ltal√°nos√≠that√≥bb mint√°kat tanulhatnak. A m√≥dos√≠t√°s jelentheti egy k√©p elforgat√°s√°nak be√°ll√≠t√°s√°t, megford√≠t√°s√°t, kiv√°g√°s√°t vagy valami hasonl√≥t.

Ezzel szimul√°ljuk azt az adatfajt√°t, amelyre a modell a val√≥ vil√°gban felhaszn√°lhat√≥.

Ha egy pizza vs. steak alkalmaz√°st k√©sz√≠t√ºnk, nem biztos, hogy a felhaszn√°l√≥ink √°ltal k√©sz√≠tett √∂sszes k√©p hasonl√≥ be√°ll√≠t√°s√∫, mint a k√©pz√©si adataink. Az adatb≈ëv√≠t√©s haszn√°lata egy m√°sik m√≥dot ad arra, hogy megakad√°lyozzuk a t√∫lilleszt√©st, √©s ez√°ltal √°ltal√°nos√≠that√≥bb√° tegy√ºk a modell√ºnket.

üîë Megjegyz√©s: Az adatb≈ëv√≠t√©st √°ltal√°ban csak a k√©pz√©si adatokon v√©gezz√ºk. Az ImageDataGenerator be√©p√≠tett adatb≈ëv√≠t√©si param√©tereinek haszn√°lat√°val a k√©peinket √∫gy hagyjuk, ahogyan azok a k√∂nyvt√°rakban vannak, de a modellbe val√≥ bet√∂lt√©skor v√©letlenszer≈±en manipul√°ljuk ≈ëket.
"""

# Import data and augment it from training directory
print("Augmented training images:")
train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                                                                   target_size=(224, 224),
                                                                   batch_size=32,
                                                                   class_mode='binary',
                                                                   shuffle=False) # Don't shuffle for demonstration purposes, usually a good thing to shuffle

# Create non-augmented data batches
print("Non-augmented training images:")
train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size=(224, 224),
                                               batch_size=32,
                                               class_mode='binary',
                                               shuffle=False) # Don't shuffle for demonstration purposes

print("Unchanged test images:")
test_data = test_datagen.flow_from_directory(test_dir,
                                             target_size=(224, 224),
                                             batch_size=32,
                                             class_mode='binary')

# Get data batch samples
images, labels = train_data.next()
augmented_images, augmented_labels = train_data_augmented.next() # Note: labels aren't augmented, they stay the same

# Show original image and augmented image
random_number = random.randint(0, 32) # we're making batches of size 32, so we'll get a random instance
plt.imshow(images[random_number])
plt.title(f"Original image")
plt.axis(False)
plt.figure()
plt.imshow(augmented_images[random_number])
plt.title(f"Augmented image")
plt.axis(False);

"""Miut√°n v√©gigment√ºnk az eredeti √©s a kiterjesztett k√©pek mint√°j√°n, l√°thatunk n√©h√°ny p√©ld√°t a gyakorl√≥ k√©peken v√©gzett √°talak√≠t√°sokra.

Vegye √©szre, hogy a kiterjesztett k√©pek n√©melyike az eredeti k√©p enyh√©n torz√≠tott v√°ltozat√°nak t≈±nik. Ez azt jelenti, hogy a modell√ºnk k√©nytelen lesz megpr√≥b√°lni mint√°kat tanulni a nem t√∂k√©letes k√©peken, ami gyakran el≈ëfordul, amikor val√≥s k√©peket haszn√°lunk.

#ü§î K√©rd√©s: Haszn√°ljak adatb≈ëv√≠t√©st? √âs mennyire kell b≈ëv√≠tenem?

Az adatb≈ëv√≠t√©s egy m√≥dja annak, hogy megpr√≥b√°ljuk megakad√°lyozni a modell t√∫lilleszt√©s√©t. Ha a modellje t√∫lilleszkedik (pl. a valid√°ci√≥s vesztes√©g folyamatosan n√∂vekszik), akkor √©rdemes megpr√≥b√°lkoznia az adatn√∂vel√©s alkalmaz√°s√°val.

Arra vonatkoz√≥an, hogy mennyire kell az adatokat b≈ëv√≠teni, nincs meghat√°rozott gyakorlat. A legjobb, ha megn√©zi az ImageDataGenerator oszt√°ly opci√≥it, √©s elgondolkodik azon, hogy az √ñn felhaszn√°l√°si eset√©hez tartoz√≥ modellnek milyen el≈ëny√∂s lehet n√©mi adatn√∂vel√©s.

Most, hogy megvan a kib≈ëv√≠tett adatunk, pr√≥b√°ljuk meg √∫jrailleszteni rajta a modellt, √©s n√©zz√ºk meg, hogyan befoly√°solja a k√©pz√©st.

Ugyanazt a modellt fogjuk haszn√°lni, mint a model_5.
"""

# Create the model (same as model_5)
model_6 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(pool_size=2), # reduce number of features by half
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

# Compile the model
model_6.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

# Fit the model
history_6 = model_6.fit(train_data_augmented, # changed to augmented training data
                        epochs=5,
                        steps_per_epoch=len(train_data_augmented),
                        validation_data=test_data,
                        validation_steps=len(test_data))

"""# ü§î K√©rd√©s: Mi√©rt nem kapott a modell√ºnk kezdetben nagyon j√≥ eredm√©nyeket a gyakorl√≥halmazon?

Az√©rt, mert amikor l√©trehoztuk a train_data_augmented-t, kikapcsoltuk az adatok kever√©s√©t a shuffle=False haszn√°lat√°val, ami azt jelenti, hogy a modell√ºnk egyszerre csak egy t√©telben l√°t egyfajta k√©pet.

P√©ld√°ul a pizza oszt√°ly ker√ºl el≈ësz√∂r bet√∂lt√©sre, mert ez az els≈ë oszt√°ly. √çgy a teljes√≠tm√©nyt csak egyetlen oszt√°lyon m√©rj√ºk, nem pedig mindk√©t oszt√°lyon. A valid√°ci√≥s adatok teljes√≠tm√©nye folyamatosan javul, mert keveredett adatokat tartalmaz.

Mivel a shuffle=False √©rt√©ket csak demonstr√°ci√≥s c√©llal √°ll√≠tottuk be (√≠gy ugyanazt a kiterjesztett √©s nem kiterjesztett k√©pet √°br√°zolhattuk), ezt a j√∂v≈ëbeni adatgener√°torokn√°l a shuffle=True √©rt√©k be√°ll√≠t√°s√°val jav√≠thatjuk.

Azt is √©szrevehett√ºk, hogy az egyes epoch√°k hosszabb ideig tartanak, amikor a kiterjesztett adatokkal edz√ºnk, mint amikor nem kiterjesztett adatokkal (~25s per epocha vs. ~10s per epocha).

Ez az√©rt van, mert az ImageDataGenerator p√©ld√°ny a modellbe bet√∂lt√©skor b≈ëv√≠ti az adatokat. Ennek el≈ënye, hogy az eredeti k√©peket v√°ltozatlanul hagyja. H√°tr√°nya, hogy hosszabb ideig tart a bet√∂lt√©s√ºk.

"""

# Check model's performance history training on augmented data
plot_loss_curves(history_6)

"""√ögy t≈±nik, hogy az √©rv√©nyes√≠t√©si vesztes√©gg√∂rb√©nk j√≥ ir√°nyba halad, de egy kicsit ugr√°sszer≈± (a legide√°lisabb vesztes√©gg√∂rbe nem t√∫l t√ºsk√©s, hanem egyenletes ereszked√©s, azonban a t√∂k√©letesen egyenletes vesztes√©gg√∂rbe a mes√©vel egyen√©rt√©k≈±).

L√°ssuk, mi t√∂rt√©nik, ha megkeverj√ºk a kieg√©sz√≠tett k√©pz√©si adatokat.
"""

# Import data and augment it from directories
train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,
                                                                            target_size=(224, 224),
                                                                            batch_size=32,
                                                                            class_mode='binary',
                                                                            shuffle=True) # Shuffle data (default)

# Create the model (same as model_5 and model_6)
model_7 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

# Compile the model
model_7.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

# Fit the model
history_7 = model_7.fit(train_data_augmented_shuffled, # now the augmented data is shuffled
                        epochs=5,
                        steps_per_epoch=len(train_data_augmented_shuffled),
                        validation_data=test_data,
                        validation_steps=len(test_data))

# Check model's performance history training on augmented data
plot_loss_curves(history_7)

"""Figyelj√ºk meg, hogy a model_7 modell eset√©ben a teljes√≠tm√©ny a gyakorl√≥ adathalmazon szinte azonnal javul a model_6-hoz k√©pest. Ez az√©rt van, mert a flow_from_directory m√≥dszerben a shuffle=True param√©ter haszn√°lat√°val megkevert√ºk a k√©pz√©si adatokat, amikor √°tadtuk azokat a modellnek.

Ez azt jelenti, hogy a modell minden egyes k√∂tegben l√°thatott p√©ld√°kat mind a pizza, mind a steak k√©pekre, √©s viszont az alapj√°n √©rt√©kelhet≈ë, amit mindk√©t k√©pb≈ël tanult, nem pedig csak az egyik fajt√°b√≥l.

A vesztes√©gg√∂rb√©ink is egy kicsit sim√°bbnak t≈±nnek a kevert adatokkal (a history_6 √©s a history_7 √∂sszehasonl√≠t√°sa).

#El≈ërejelz√©s k√©sz√≠t√©se a betan√≠tott modellel

Mit √©r egy betan√≠tott modell, ha nem tudunk vele el≈ërejelz√©seket k√©sz√≠teni?

Hogy igaz√°n kipr√≥b√°lhassuk, felt√∂lt√ºnk n√©h√°ny saj√°t k√©pet, √©s megn√©zz√ºk, hogyan m≈±k√∂dik a modell.

El≈ësz√∂r is eml√©keztess√ºk magunkat az oszt√°lynevekre, √©s n√©zz√ºk meg a k√©pet, amelyen tesztelni fogjuk.
"""

# View our example image
!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg
steak = mpimg.imread("03-steak.jpeg")
plt.imshow(steak)
plt.axis(False);

# Check the shape of our image
steak.shape

"""Mivel a modell√ºnk (224, 224, 3) alak√∫ k√©peket vesz fel, √°t kell alak√≠tanunk az egy√©ni k√©p√ºnket, hogy a modell√ºnkkel haszn√°lhassuk.

Ehhez a k√©p√ºnket a tf.io.read_file (f√°jlok beolvas√°s√°hoz) √©s a tf.image (k√©p√ºnk √°tm√©retez√©s√©hez √©s tenzorr√° alak√≠t√°s√°hoz) seg√≠ts√©g√©vel import√°lhatjuk √©s dek√≥dolhatjuk.

üîë Megjegyz√©s: Ahhoz, hogy a modell√ºnk el≈ërejelz√©seket tudjon k√©sz√≠teni nem l√°tott adatokra, p√©ld√°ul saj√°t, egy√©ni k√©peinkre, az egy√©ni k√©pnek ugyanolyan alak√∫nak kell lennie, mint amilyenre a modell√ºnket betan√≠tottuk. √Åltal√°nosabban fogalmazva, ahhoz, hogy az egy√©ni adatokon el≈ërejelz√©seket tudjon k√©sz√≠teni, ugyanolyan alak√∫nak kell lennie, mint amilyenre a modellj√©t betan√≠tott√°k.

#K√©sz√≠ts√ºnk egy f√ºggv√©nyt az adatok beolvas√°s√°ra √©s √°talak√≠t√°s√°ra
"""

# Create a function to import an image and resize it to be able to be used with our model
def load_and_prep_image(filename, img_shape=224):
  """
  Reads an image from filename, turns it into a tensor
  and reshapes it to (img_shape, img_shape, colour_channel).
  """
  # Read in target file (an image)
  img = tf.io.read_file(filename)

  # Decode the read file into a tensor & ensure 3 colour channels
  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)
  img = tf.image.decode_image(img, channels=3) #tensor formatum

  # Resize the image (to the same size our model was trained on)
  img = tf.image.resize(img, size = [img_shape, img_shape])

  # Rescale the image (get all values between 0 and 1)
  img = img/255.
  return img

# Load in and preprocess our custom image
steak = load_and_prep_image("03-steak.jpeg")
steak

# Make a prediction on our custom image (spoiler: this won't work)
model_7.predict(steak)

"""Van m√©g egy probl√©ma...

B√°r a k√©p√ºnk ugyanolyan alak√∫, mint azok a k√©pek, amelyeken a modell√ºnket betan√≠tott√°k, m√©g mindig hi√°nyzik egy dimenzi√≥.

Eml√©kszel, hogy a modell√ºnket t√©telesen k√©pezt√ºk ki?

Nos, a t√©telek m√©rete lesz az els≈ë dimenzi√≥.

Teh√°t a val√≥s√°gban a modell√ºnket a (batch_size, 224, 224, 3) alak√∫ adatokon k√©pezt√ºk ki.

Ezt √∫gy tudjuk kijav√≠tani, hogy a tf.expand_dims seg√≠ts√©g√©vel hozz√°adunk egy pluszt az egy√©ni k√©ptenzorunkhoz.
"""

# Add an extra axis
print(f"Shape before new dimension: {steak.shape}")
steak = tf.expand_dims(steak, axis=0) # add an extra dimension at axis 0
#steak = steak[tf.newaxis, ...] # alternative to the above, '...' is short for 'every other dimension'
print(f"Shape after new dimension: {steak.shape}")
#steak

# Make a prediction on custom image tensor
pred = model_7.predict(steak)
pred

"""Ahh, a j√≥slatok el≈ërejelz√©si val√≥sz√≠n≈±s√©g form√°j√°ban jelennek meg. M√°s sz√≥val ez azt jelenti, hogy a k√©p milyen val√≥sz√≠n≈±s√©ggel tartozik az egyik vagy a m√°sik oszt√°lyba.

Mivel bin√°ris oszt√°lyoz√°si probl√©m√°val dolgozunk, ha az el≈ërejelz√©si val√≥sz√≠n≈±s√©g 0,5 f√∂l√∂tt van, a modell szerint az el≈ërejelz√©s nagy val√≥sz√≠n≈±s√©ggel a pozit√≠v oszt√°ly (1. oszt√°ly).

Ha pedig az el≈ërejelz√©si val√≥sz√≠n≈±s√©g 0,5 alatt van, akkor a modell szerint a megj√≥solt oszt√°ly nagy val√≥sz√≠n≈±s√©ggel a negat√≠v oszt√°ly (0. oszt√°ly).

üîë Megjegyz√©s: A 0,5-es hat√°r√©rt√©k tetsz√©s szerint m√≥dos√≠that√≥. P√©ld√°ul be√°ll√≠thatja a hat√°r√©rt√©ket √∫gy, hogy 0,8 √©s t√∂bb legyen a pozit√≠v oszt√°ly, √©s 0,2 a negat√≠v oszt√°ly eset√©ben. Ez azonban szinte mindig megv√°ltoztatja a modell teljes√≠tm√©nymutat√≥it, ez√©rt gy≈ëz≈ëdj√∂n meg r√≥la, hogy azok a megfelel≈ë ir√°nyba v√°ltoznak.

De pozit√≠v √©s negat√≠v oszt√°lyt mondani nem sok √©rtelme van, amikor pizz√°val üçï √©s steakkel ü•© dolgozunk...

√çrjunk teh√°t egy kis f√ºggv√©nyt, amely a predikci√≥kat oszt√°lynev√ºkk√© alak√≠tja, majd a c√©lk√©pet √°br√°zolja.
"""

pred_class = class_names[int(tf.round(pred)[0][0])]
pred_class

pred.shape

def pred_and_plot(model, filename, class_names):
  """
  Imports an image located at filename, makes a prediction on it with
  a trained model and plots the image with the predicted class as the title.
  """
  # Import the target image and preprocess it
  img = load_and_prep_image(filename)

  # Make a prediction
  pred = model.predict(tf.expand_dims(img, axis=0))

  # Get the predicted class
  pred_class = class_names[int(tf.round(pred)[0][0])]

  # Plot the image and predicted class
  plt.imshow(img)
  plt.title(f"Prediction: {pred_class}")
  plt.axis(False);

# Test our model on a custom image
pred_and_plot(model_7, "03-steak.jpeg", class_names)

"""#Modell√ºnk ment√©se √©s bet√∂lt√©se
Ha m√°r betan√≠tott√°l egy modellt, val√≥sz√≠n≈±leg szeretn√©d elmenteni √©s bet√∂lteni valahova m√°shova.

Ehhez haszn√°lhatjuk a save √©s load_model f√ºggv√©nyeket.
"""

# Save a model
model_7.save("saved_trained_model")

# Load in a model and evaluate it
loaded_model_7 = tf.keras.models.load_model("saved_trained_model")
loaded_model_7.evaluate(test_data)

"""#H√°zi feladat

√âp√≠tsen k√©poszt√°lyoz√≥ modellt az al√°bbi adatk√©szlet felhaszn√°l√°s√°val! Alkalmazzon adatb≈ëv√≠t√©st, kis√©rletezzen t√∂bb modell l√©trehoz√°s√°val!
√ârt√©kelje a modellt, majd mentse el azt!
"""

import zipfile

# Download zip file of 10_food_classes images
# See how this data was created - https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip

# Unzip the downloaded file
zip_ref = zipfile.ZipFile("10_food_classes_all_data.zip", "r")
zip_ref.extractall()
zip_ref.close()

import pathlib
import numpy as np
data_dir = pathlib.Path("10_food_classes_all_data/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")])) # Create a list of class_nmaes from the subdirectories
print(class_names)